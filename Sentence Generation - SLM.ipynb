{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "SDYPjH3wWqkk"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "%pip install accelerate bitsandbytes -q\n",
        "!pip install -Uq transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9U63Yki1kVLg",
        "outputId": "0f69ef2d-bc88-4a14-f3e9-7a62ef221a5c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'status': 'ok', 'restart': True}"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Automatically restart kernel after installs so that your environment can access the new packages\n",
        "import IPython\n",
        "\n",
        "app = IPython.Application.instance()\n",
        "app.kernel.do_shutdown(True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PMXnx-kfgqnH"
      },
      "source": [
        "# init setup\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QC4s3UccJxG8",
        "outputId": "52b4b6f6-c0d7-4195-d53e-f95b32839eb3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "31\n",
            "Jul\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "\n",
        "# Get the current time struct\n",
        "current_time = time.localtime()\n",
        "\n",
        "# Extract date and short month name\n",
        "date = time.strftime(\"%d\", current_time)\n",
        "short_month = time.strftime(\"%b\", current_time)\n",
        "\n",
        "print(date)\n",
        "print(short_month)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s8YAM1Mb2PpJ"
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "path = Path('/content/drive/Shareddrives/sentence_genration')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A-ZYWjR1ggu6",
        "outputId": "693314e1-d782-4d54-889b-04f9be398068"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "base_path='/content/drive/MyDrive/Sentiment_Analysis_Roberta/'\n",
        "base_intent_path='/content/drive/MyDrive/Intent_Analysis/'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZVSCyLqkgwAo"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "# adding utils to the system path\n",
        "sys.path.insert(0, base_path+'SA_utils')\n",
        "sys.path.insert(0, base_intent_path+'intent_utils')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cRKinNATg-1L",
        "outputId": "d372bd2b-d9a6-4aae-f1ef-0807958276af"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading files...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Files loaded.\n"
          ]
        }
      ],
      "source": [
        "from main import *\n",
        "from config import current_possible_intents as intents, MOBILE_MODEL_PTH, MOBILE_TOKENIZER_PTH, Mobile_competitor_dict_pth, Mobile_intent_dict_pth_and_sheet_info\n",
        "from intent_utils import *\n",
        "from pro_con_sa import *\n",
        "from subdomain_analysis_funcs import *\n",
        "from subdomain_analysis_funcs import *"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "myIsitCxgb56"
      },
      "source": [
        "# Loading data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FPxlwbKgdrUe"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "from google.colab import drive\n",
        "from pathlib import Path\n",
        "import sys\n",
        "from main import *\n",
        "from config import current_possible_intents as intents, MOBILE_MODEL_PTH, MOBILE_TOKENIZER_PTH, Mobile_competitor_dict_pth, Mobile_intent_dict_pth_and_sheet_info\n",
        "from intent_utils import *\n",
        "from pro_con_sa import *\n",
        "from subdomain_analysis_funcs import *\n",
        "from subdomain_analysis_funcs import *\n",
        "import torch\n",
        "import pandas as pd\n",
        "from subdomain_analysis_funcs import subdomain_splitter\n",
        "import IPython\n",
        "from transformers import pipeline, AutoTokenizer, BitsAndBytesconfig, AutoModelForCausalLM\n",
        "from tqdm import tqdm\n",
        "import pickle\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
        "from tqdm import tqdm\n",
        "from numba import cuda\n",
        "import gc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5W-jptTgWwrp"
      },
      "outputs": [],
      "source": [
        "# items_to_do_direct_opp=[\n",
        "#     '^(?:(?!saved?|back ?-?up|\\\\beditor\\\\b|\\\\beras[eding]*\\\\b|\\\\bedit[ingedabl]*|google|\\\\bplayback|\\\\bscreen|\\\\bdisplay|drive\\\\b|bright[erst]*\\\\b|\\\\bu?n?responsive\\\\b).)*(\\\\bimages?\\\\b|\\\\bpictures?\\\\b|\\\\bpics?\\\\b|\\\\bportraits?\\\\b|\\\\bphotos?\\\\b)(?!.*back ?-?up|(?!.* without).*\\\\beditor\\\\b|erase\\\\b|(?!.* without).*\\\\bedit[edingabl]*\\\\b|.*\\\\bplayback\\\\b|.*\\\\bscreen|.*\\\\bdisplay|.*drive\\\\b|.*bright\\\\b|(?!.* without).*\\\\bsettings?\\\\b|.*\\\\bu?n?responsive\\\\b|saved?)',\n",
        "#     ]\n",
        "\n",
        "import pickle\n",
        "if 'Subdom_re_dict' in globals() :\n",
        "    pass\n",
        "\n",
        "else :\n",
        "    file_path = '/content/drive/Shareddrives/sentence_genration/misc/Subdom_re_dict_29_Jul.pkl'\n",
        "    with open(file_path, 'rb') as f:\n",
        "        Subdom_re_dict = pickle.load(f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x-YMTCTEgfHC",
        "outputId": "fd6a58e0-7cb8-47ab-cb71-e9eff33a33ea"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "^(?:(?!saved?|back ?-?up|\\beditor\\b|\\beras[eding]*\\b|\\bedit[ingedabl]*|google|\\bplayback|\\bscreen|\\bdisplay|drive\\b|bright[erst]*\\b|\\bu?n?responsive\\b).)*(\\bimages?\\b|\\bpictures?\\b|\\bpics?\\b|\\bportraits?\\b|\\bphotos?\\b)(?!.*back ?-?up|(?!.* without).*\\beditor\\b|erase\\b|(?!.* without).*\\bedit[edingabl]*\\b|.*\\bplayback\\b|.*\\bscreen|.*\\bdisplay|.*drive\\b|.*bright\\b|(?!.* without).*\\bsettings?\\b|.*\\bu?n?responsive\\b|saved?)\n",
            "Camera\n",
            " 1.0    1061\n",
            "-1.0      68\n",
            "Name: count, dtype: int64\n",
            "\n",
            "^(?:(?!streami?n?g?|watchi?n?g?|back ?-?up|\\beditor\\b|\\beras[edings]*\\b|\\bedit[ingedabl]*\\b|\\bplayback|\\bscreen|\\bdisplay|drive\\b|\\bplay|\\bwatch|\\bu?n?responsive\\b).)*(?:\\bvideos?\\b|\\bvedios?\\b)(?! back ?-?up|(?!.* without).*\\beditor\\b|.*\\beras[edings]*\\b|(?!.* without).*\\bedit[edingabl]*\\b|.*\\bplayback\\b|.*\\bscreen|.*\\bdisplay|.*drive\\b| calls?i?n?g?s?\\b|.*\\bplay|.*settings?|.*\\bu?n?responsive\\b|.*streami?n?g?|.*watchi?n?g?|\\s*appointment)\n",
            "Camera\n",
            " 1.0    222\n",
            "-1.0     22\n",
            "Name: count, dtype: int64\n",
            "\n",
            "video quality\n",
            "Camera\n",
            "1.0    16\n",
            "Name: count, dtype: int64\n",
            "\n",
            "resolution|(?<!google |series )pixels?\\b(?! ?,?[a-zA-Z]?\\d+| phone| xl| mobile| \\b[a-zA-Z]{1}\\b| fold| exclusive features?| features?| \\bitems| one| \\bonly \\bfeatures| itself\\b| users?\\b| models?| devices?\\b| mobiles?\\b| experiences?\\b| forever\\b| series\\b|)|\\d{3,4}p\n",
            "Camera\n",
            " 1.0    70\n",
            "-1.0     4\n",
            "Name: count, dtype: int64\n",
            "\n",
            "capture\n",
            "Camera\n",
            " 1.0    26\n",
            "-1.0     1\n",
            "Name: count, dtype: int64\n",
            "\n",
            "megapixel\n",
            "Camera\n",
            "1.0    13\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Photography|photographers?|photographs?\n",
            "Camera\n",
            " 1.0    87\n",
            "-1.0     2\n",
            "Name: count, dtype: int64\n",
            "\n",
            "last\n",
            "Camera\n",
            " 1.0    32\n",
            "-1.0     1\n",
            "Name: count, dtype: int64\n",
            "\n",
            "perform[sance]*\n",
            "Camera\n",
            " 1.0    110\n",
            "-1.0      2\n",
            "Name: count, dtype: int64\n",
            "\n",
            "lavender\\b|\\bblack\\b|\\bolive\\b|\\bgreen\\b|\\bwhite\\b|\\bred\\b|\\bblue\\b|\\blemongrass\\b|\\bpurplelavender\\b|\\bblack\\b|\\bolive\\b|\\bgreen\\b|\\bwhite\\b|\\bred\\b|\\bblue\\b|\\blemongrass\\b|\\bpurple\n",
            "Camera\n",
            " 1.0    22\n",
            "-1.0     2\n",
            "Name: count, dtype: int64\n",
            "\n",
            "\\bCamera'?s?\\b.*\\bm?i?d?nightt?i?m?e?\\b|\\bm?i?d?nightt?i?m?e?\\b.*\\bCamera'?s?\\b\n",
            "Camera\n",
            " 1.0    88\n",
            "-1.0     6\n",
            "Name: count, dtype: int64\n",
            "\n",
            "\\b\\d+mp\\b|\\bmp\\b\n",
            "\n",
            "Camera\n",
            " 1.0    52\n",
            "-1.0     5\n",
            "Name: count, dtype: int64\n",
            "\n",
            "zoom[sing]*\n",
            "Camera\n",
            " 1.0    141\n",
            "-1.0     18\n",
            "Name: count, dtype: int64\n",
            "\n",
            "lens\n",
            "Camera\n",
            " 1.0    34\n",
            "-1.0     3\n",
            "Name: count, dtype: int64\n",
            "\n",
            "(?<!screen )shot[s]*\n",
            "Camera\n",
            " 1.0    79\n",
            "-1.0     1\n",
            "Name: count, dtype: int64\n",
            "\n",
            "shot[s]*\n",
            "Camera\n",
            " 1.0    79\n",
            "-1.0     1\n",
            "Name: count, dtype: int64\n",
            "\n",
            "(?:\\bimages?\\b|\\bpictures?\\b|\\bpics?\\b|\\bportraits?\\b|\\bphotos?\\b)(?!.*vide?o?s?\\b).*\\bm?i?d?nightt?i?m?e?\\b(?!.*day|.*vide?o?s?\\b)|\\bm?i?d?nightt?i?m?e?\\b(?!.*vide?o?s?\\b).*(?:\\bimages?\\b|\\bpictures?\\b|\\bpics?\\b|\\bportraits?\\b|\\bphotos?\\b)(?!.*day|.*vide?o?s?\\b)\n",
            "Camera\n",
            " 1.0    50\n",
            "-1.0     1\n",
            "Name: count, dtype: int64\n",
            "\n",
            "lighting\n",
            "Camera\n",
            " 1.0    22\n",
            "-1.0     1\n",
            "Name: count, dtype: int64\n",
            "\n",
            "blurry\n",
            "Camera\n",
            " 1.0    9\n",
            "-1.0    5\n",
            "Name: count, dtype: int64\n",
            "\n",
            "selfies?\n",
            "Camera\n",
            " 1.0    31\n",
            "-1.0     5\n",
            "Name: count, dtype: int64\n",
            "\n",
            "close[- ]{0,3}up\n",
            "Camera\n",
            "1.0    7\n",
            "Name: count, dtype: int64\n",
            "\n",
            "night \\s*sight\n",
            "Camera\n",
            " 1.0    13\n",
            "-1.0     1\n",
            "Name: count, dtype: int64\n",
            "\n",
            "(clear|crisp|sharp)[^.]*(view)|graphic[als]*|visibl[ityle]*\\b|visual[lys]*\\b|bright[erns]*(?!\\s*side)\n",
            "Camera\n",
            " 1.0    44\n",
            "-1.0     8\n",
            "Name: count, dtype: int64\n",
            "\n",
            "speed\n",
            "Camera\n",
            "1.0    74\n",
            "Name: count, dtype: int64\n",
            "\n",
            "\\bCamera'?s?\\b.*\\bm?i?d?dayt?i?m?e?\\b|\\bm?i?d?dayt?i?m?e?\\b.*\\bCamera'?s?\\b\n",
            "Camera\n",
            "1.0    74\n",
            "Name: count, dtype: int64\n",
            "\n",
            "shutter\n",
            "Camera\n",
            " 1.0    8\n",
            "-1.0    3\n",
            "Name: count, dtype: int64\n",
            "\n",
            "auto[- ]{0,3}focus\n",
            "Camera\n",
            " 1.0    3\n",
            "-1.0    3\n",
            "Name: count, dtype: int64\n",
            "\n",
            "\\bvide?o?s?\\b(?!.*\\bimages?\\b|.*\\bpictures?\\b|.*\\bpics?\\b|.*\\bportraits?\\b|.*\\bphotos?\\b).*\\bm?i?d?dayt?i?m?e?\\b(?!.*night|.*\\bimages?\\b|.*\\bpictures?\\b|.*\\bpics?\\b|.*\\bportraits?\\b|.*\\bphotos?\\b)|\\bm?i?d?dayt?i?m?e?\\b(?!.*\\bimages?\\b|.*\\bpictures?\\b|.*\\bpics?\\b|.*\\bportraits?\\b|.*\\bphotos?\\b).*\\bvide?o?s?\\b(?!.*night|.*\\bimages?\\b|.*\\bpictures?\\b|.*\\bpics?\\b|.*\\bportraits?\\b|.*\\bphotos?\\b)\n",
            "Camera\n",
            "1.0    8\n",
            "Name: count, dtype: int64\n",
            "\n",
            "definition\n",
            "Camera\n",
            "1.0    6\n",
            "Name: count, dtype: int64\n",
            "\n",
            "(?:\\bimages?\\b|\\bpictures?\\b|\\bpics?\\b|\\bportraits?\\b|\\bphotos?\\b)(?!.*vide?o?s?\\b).*\\bm?i?d?dayt?i?m?e?\\b(?!.*night|.*vide?o?s?\\b)|\\bm?i?d?dayt?i?m?e?\\b(?!.*vide?o?s?\\b).*(?:\\bimages?\\b|\\bpictures?\\b|\\bpics?\\b|\\bportraits?\\b|\\bphotos?\\b)(?!.*night|.*vide?o?s?\\b)\n",
            "Camera\n",
            " 1.0    17\n",
            "-1.0     1\n",
            "Name: count, dtype: int64\n",
            "\n",
            "wide[- ]{0,3}angle\n",
            "Camera\n",
            "1.0    4\n",
            "Name: count, dtype: int64\n",
            "\n",
            "\\bvide?o?s?\\b(?!.*\\bimages?\\b|.*\\bpictures?\\b|.*\\bpics?\\b|.*\\bportraits?\\b|.*\\bphotos?\\b).*\\bm?i?d?nightt?i?m?e?\\b(?!.*day|.*\\bimages?\\b|.*\\bpictures?\\b|.*\\bpics?\\b|.*\\bportraits?\\b|.*\\bphotos?\\b)|\\bm?i?d?nightt?i?m?e?\\b(?!.*\\bimages?\\b|.*\\bpictures?\\b|.*\\bpics?\\b|.*\\bportraits?\\b|.*\\bphotos?\\b).*\\bvide?o?s?\\b(?!.*day|.*\\bimages?\\b|.*\\bpictures?\\b|.*\\bpics?\\b|.*\\bportraits?\\b|.*\\bphotos?\\b)\n",
            "Camera\n",
            " 1.0    2\n",
            "-1.0    1\n",
            "Name: count, dtype: int64\n",
            "\n",
            "(?:\\bimages?\\b|\\bpictures?\\b|\\bpics?\\b|\\bportraits?\\b|\\bphotos?\\b).*\\bvide?o?s?\\b.*\\bm?i?d?dayt?i?m?e?\\b|\\bvide?o?s?\\b.*(?:\\bimages?\\b|\\bpictures?\\b|\\bpics?\\b|\\bportraits?\\b|\\bphotos?\\b).*\\bm?i?d?dayt?i?m?e?\\b|\\bm?i?d?dayt?i?m?e?\\b.*(?:\\bimages?\\b|\\bpictures?\\b|\\bpics?\\b|\\bportraits?\\b|\\bphotos?\\b).*\\bvide?o?s?\\b|\\bm?i?d?dayt?i?m?e?\\b.*\\bvide?o?s?\\b.*(?:\\bimages?\\b|\\bpictures?\\b|\\bpics?\\b|\\bportraits?\\b|\\bphotos?\\b)\n",
            "Camera\n",
            "1.0    4\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Space Zoom\n",
            "Camera\n",
            "1.0    1\n",
            "Name: count, dtype: int64\n",
            "\n",
            "(?:\\bimages?\\b|\\bpictures?\\b|\\bpics?\\b|\\bportraits?\\b|\\bphotos?\\b)(?!.*vide?o?s?\\b).*\\bdaylight\\b(?!.*day|.*vide?o?s?\\b)|\\bdaylight\\b(?!.*vide?o?s?\\b).*(?:\\bimages?\\b|\\bpictures?\\b|\\bpics?\\b|\\bportraits?\\b|\\bphotos?\\b)(?!.*day|.*vide?o?s?\\b)\n",
            "Camera\n",
            "1.0    1\n",
            "Name: count, dtype: int64\n",
            "\n",
            "mega \\bpixel\n",
            "Camera\n",
            "1.0    1\n",
            "Name: count, dtype: int64\n",
            "\n",
            "(?:\\bimages?\\b|\\bpictures?\\b|\\bpics?\\b|\\bportraits?\\b|\\bphotos?\\b).*\\bvide?o?s?\\b.*\\bm?i?d?nightt?i?m?e?\\b|\\bvide?o?s?\\b.*(?:\\bimages?\\b|\\bpictures?\\b|\\bpics?\\b|\\bportraits?\\b|\\bphotos?\\b).*\\bm?i?d?nightt?i?m?e?\\b|\\bm?i?d?nightt?i?m?e?\\b.*(?:\\bimages?\\b|\\bpictures?\\b|\\bpics?\\b|\\bportraits?\\b|\\bphotos?\\b).*\\bvide?o?s?\\b|\\bm?i?d?nightt?i?m?e?\\b.*\\bvide?o?s?\\b.*(?:\\bimages?\\b|\\bpictures?\\b|\\bpics?\\b|\\bportraits?\\b|\\bphotos?\\b)\n",
            "Camera\n",
            "1.0    2\n",
            "Name: count, dtype: int64\n",
            "\n"
          ]
        }
      ],
      "source": [
        "for i in Subdom_re_dict:\n",
        "    temp_df=pd.DataFrame(Subdom_re_dict[i])\n",
        "    # print(temp_df.info())\n",
        "    # break\n",
        "    print(i)\n",
        "    print(temp_df['Camera'].value_counts())\n",
        "    print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O1d0HyIahyhB",
        "outputId": "bb6e0d8a-2a66-4ff3-b397-18f63942a18a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "37"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(Subdom_re_dict)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EisJnqQFIIKn"
      },
      "source": [
        "# Final Funcs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gWPfivI0AgNt"
      },
      "source": [
        "## Model Loading"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8-4dnT_2Ai9v"
      },
      "outputs": [],
      "source": [
        "def load_llama3(model_id = 'Orenguteng/Llama-3-8B-Lexi-Uncensored', model_path = '/content/drive/Shareddrives/sentence_genration/llama3/untrained/model'):\n",
        "\n",
        "\n",
        "  compute_dtype = getattr(torch, \"float16\")\n",
        "  bnb_config = BitsAndBytesconfig(\n",
        "      load_in_4bit=True,\n",
        "      bnb_4bit_use_double_quant=False,\n",
        "      bnb_4bit_quant_type=\"nf4\",\n",
        "      bnb_4bit_compute_dtype=compute_dtype,\n",
        "  )\n",
        "\n",
        "  model = AutoModelForCausalLM.from_pretrained(\n",
        "      model_path,\n",
        "      device_map=\"auto\",\n",
        "      quantization_config=bnb_config,\n",
        "  )\n",
        "\n",
        "  tokenizer = AutoTokenizer.from_pretrained(\n",
        "      model_id,\n",
        "      # token=access_token,\n",
        "      cache_dir='/content/drive/Shareddrives/sentence_genration/mistral/Mistral-7B-v0.3/Tokenizer',\n",
        "\n",
        "      padding_side='left',\n",
        "      quantization_config=bnb_config,\n",
        "\n",
        "      )\n",
        "  tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "\n",
        "  return model, tokenizer\n",
        "def load_mistral(model_id = 'mistralai/Mistral-7B-Instruct-v0.3',\n",
        "                 model_path = '/content/drive/Shareddrives/sentence_genration/mistral/Mistral-7B-Instruct-v0.3/SavedModel',\n",
        "                 access_token = None #(Optional) Put your access token here incase not downloaded or cache dir is empty\n",
        "                 ):\n",
        "\n",
        "\n",
        "  compute_dtype = getattr(torch, \"float16\")\n",
        "  bnb_config = BitsAndBytesconfig(\n",
        "      load_in_4bit=True,\n",
        "      bnb_4bit_use_double_quant=False,\n",
        "      bnb_4bit_quant_type=\"nf4\",\n",
        "      bnb_4bit_compute_dtype=compute_dtype,\n",
        "  )\n",
        "  if not access_token:\n",
        "    model = AutoModelForCausalLM.from_pretrained(\n",
        "        model_path,\n",
        "        device_map=\"auto\",\n",
        "        quantization_config=bnb_config,\n",
        "    )\n",
        "    tokenizer = AutoTokenizer.from_pretrained(\n",
        "        model_id,\n",
        "        # token=access_token,\n",
        "        cache_dir='/content/drive/Shareddrives/sentence_genration/mistral/Mistral-7B-Instruct-v0.3/Tokenizer',\n",
        "\n",
        "        padding_side='left',\n",
        "        quantization_config=bnb_config,\n",
        "\n",
        "        )\n",
        "\n",
        "\n",
        "  else:\n",
        "    model = AutoModelForCausalLM.from_pretrained(\n",
        "        model_id,\n",
        "        cache_dir='/content/drive/Shareddrives/sentence_genration/mistral/Mistral-7B-v0.3/Tokenizer',\n",
        "        token=access_token,\n",
        "        device_map=\"auto\",\n",
        "        quantization_config=bnb_config,\n",
        "    )\n",
        "    tokenizer = AutoTokenizer.from_pretrained(\n",
        "        model_id,\n",
        "        token=access_token,\n",
        "        cache_dir='/content/drive/Shareddrives/sentence_genration/mistral/Mistral-7B-v0.3/Tokenizer',\n",
        "\n",
        "        padding_side='left',\n",
        "        quantization_config=bnb_config,\n",
        "\n",
        "        )\n",
        "\n",
        "  tokenizer.pad_token = tokenizer.eos_token\n",
        "  return model, tokenizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "njUx7_FqIOUu"
      },
      "source": [
        "# Paraphrase Sentence (Llama3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RI58ZySTIOUx"
      },
      "outputs": [],
      "source": [
        "class ParaphraseDataset(Dataset):\n",
        "    def __init__(self, sentences, n_sentences_to_generate, pos_neg='positive'):\n",
        "        self.sentences = sentences\n",
        "        self.n_sentences_to_generate = n_sentences_to_generate\n",
        "        self.pos_neg=pos_neg\n",
        "        self.model, self.tokenizer = load_llama3()\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.sentences)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        sentence = self.sentences[idx]\n",
        "        actually_required_sequences=(self.n_sentences_to_generate // len(self.sentences))\n",
        "        num_return_sequences =  actually_required_sequences + 30 # At least + 30 the required sentences\n",
        "        paraphrases = self.generate_paraphrases(sentence, num_return_sequences)\n",
        "\n",
        "        # Remove duplicates\n",
        "        paraphrases = list(set(paraphrases))\n",
        "        if len(paraphrases) < actually_required_sequences:\n",
        "            paraphrases += self.generate_paraphrases(sentence, 2*(actually_required_sequences - len(paraphrases)))\n",
        "        paraphrases = paraphrases[:actually_required_sequences]\n",
        "        return paraphrases\n",
        "\n",
        "\n",
        "    def generate_paraphrases(self, sentence, num_return_sequences):\n",
        "        num_beams = num_return_sequences+20  # Ensure num_beams is at least equal to num_return_sequences or greater\n",
        "\n",
        "        prompt = f\"You are a chatbot that returns a single {self.pos_neg} sentiment synonymous or similar sentence using the reference sentences I give you, NOTE: only generate a single sentence not a sentence for each reference sentences. Just the result and nothing else. You always stick to topic of sentences. Here are the sentences:\\n\"\n",
        "        # sentence = \"Camera is very high quality.\"\n",
        "\n",
        "        # Prepare input in the required format\n",
        "        messages = [\n",
        "            {\"role\": \"system\", \"content\": prompt},\n",
        "            {\"role\": \"user\", \"content\": sentence},\n",
        "        ]\n",
        "\n",
        "        # Apply chat template and tokenize\n",
        "        inputs = self.tokenizer.apply_chat_template(messages, add_special_tokens=True, return_tensors='pt', padding=True)\n",
        "        paraphrase_batch = self.model.generate(inputs, max_new_tokens=50, num_beams=num_beams, num_return_sequences=num_return_sequences, do_sample=True, temperature=0.7)\n",
        "\n",
        "        paraphrases=[]\n",
        "        # Decode the generated output\n",
        "        for output in paraphrase_batch:\n",
        "            generated_text = self.tokenizer.decode(output, skip_special_tokens=True)\n",
        "            paraphrases.append(generated_text.split('\\n')[-1])\n",
        "        return paraphrases\n",
        "\n",
        "def generate_paraphrased_sentences(reference_sentences, n=10, b_size=1, pos_neg='positive'):\n",
        "    dataset = ParaphraseDataset(reference_sentences, n, pos_neg)\n",
        "    dataloader = DataLoader(dataset, batch_size=b_size, shuffle=False)\n",
        "\n",
        "    generated_sentences = set()  # Using a set to discard duplicates\n",
        "    total_generated = 0\n",
        "\n",
        "    for batch in dataloader:\n",
        "        for paraphrases in batch:\n",
        "            for sentence in paraphrases:\n",
        "                generated_sentences.add(sentence)\n",
        "                total_generated += 1\n",
        "\n",
        "    del dataset\n",
        "    del dataloader\n",
        "    torch.cuda.empty_cache()\n",
        "    gc.collect()\n",
        "    # device = cuda.get_current_device()\n",
        "    # device.reset()\n",
        "    return list(generated_sentences)  # Convert set back to list and take up to n sentences\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "blUyqaRvIOUy"
      },
      "outputs": [],
      "source": [
        "\n",
        "# # Example usage\n",
        "# reference_sentences = [\n",
        "#     'Camera quality is great.',\n",
        "#     'Resolution of images is amazing.',\n",
        "#     'Shutter speed is great.',\n",
        "#     'I like the images taken from it.',\n",
        "#     'The color reproduction is excellent.',\n",
        "#     'Camera is impressive.',\n",
        "#     'The pictures look sleek and modern.',\n",
        "#     'The camera app is user-friendly.',\n",
        "#     'Low light performance is superb.',\n",
        "#     'The autofocus is very fast.'\n",
        "# ]\n",
        "\n",
        "# n = 500  # Number of sentences to generate\n",
        "# pos_neg='positive'\n",
        "# positive_sentences = generate_paraphrased_sentences(reference_sentences, n, 1, pos_neg)\n",
        "# for sentence in positive_sentences:\n",
        "#     print(sentence)\n",
        "# print(len(list(set(positive_sentences))))\n",
        "\n",
        "# for i, j in enumerate(list(set(positive_sentences))):\n",
        "#     print(str(i)+' '+j)\n",
        "\n",
        "# print(len(list(set(positive_sentences))))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B1DJ4w98IOUz"
      },
      "source": [
        "## Opposite Sentence (Llama3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ORdMc5NLIOU0"
      },
      "outputs": [],
      "source": [
        "\n",
        "class OppositeSentenceDataset(Dataset):\n",
        "    def __init__(self, sentences, tokenizer):\n",
        "        self.sentences = sentences\n",
        "        self.prompt = \"You are a chatbot that returns the opposite of the sentence I give you. Just the result and nothing else. You always stick to what the sentence is originally about.\"\n",
        "        self.tokenizer = tokenizer\n",
        "    def __len__(self):\n",
        "        return len(self.sentences)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        sentence = self.sentences[idx]\n",
        "        message = [\n",
        "            {\"role\": \"system\", \"content\": self.prompt},\n",
        "            {\"role\": \"user\", \"content\": sentence},\n",
        "        ]\n",
        "        input_text = self.tokenizer.apply_chat_template(message, add_generation_prompt=True, tokenize=False)\n",
        "        return input_text, sentence\n",
        "\n",
        "def generate_opposites(model, tokenizer, sentences, batch_size=8):\n",
        "    dataset = OppositeSentenceDataset(sentences, tokenizer)\n",
        "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False, num_workers=4)\n",
        "\n",
        "    results = []\n",
        "    for batch in tqdm(dataloader, desc=\"Generating opposite sentences\"):\n",
        "        inputs, original_sentences = batch\n",
        "        inputs = tokenizer(inputs, return_tensors='pt', padding=True, truncation=False).to('cuda')\n",
        "        outputs = model.generate(**inputs, max_new_tokens=150)\n",
        "        opposites = [tokenizer.decode(output, skip_special_tokens=True) for output in outputs]\n",
        "        results.extend(opposites)\n",
        "\n",
        "    del model\n",
        "    del tokenizer\n",
        "    del dataset\n",
        "    del dataloader\n",
        "    del inputs\n",
        "    del outputs\n",
        "\n",
        "    torch.cuda.empty_cache()\n",
        "    gc.collect()\n",
        "\n",
        "    return results\n",
        "\n",
        "def generate_opposite_sentences(sentences, batch_size=42):\n",
        "    model, tokenizer = load_llama3()\n",
        "    # global model\n",
        "    # global tokenizer\n",
        "\n",
        "    opposite_sentences = generate_opposites(model, tokenizer, sentences, batch_size=batch_size)\n",
        "\n",
        "    opposite_sentences = [sentence.split(sentences[i].split(' ')[-1]+\"assistant\")[-1].strip() for i , sentence in enumerate(opposite_sentences)]\n",
        "\n",
        "    #Cleanup\n",
        "    # del model\n",
        "    # del tokenizer\n",
        "    torch.cuda.empty_cache()\n",
        "    gc.collect()\n",
        "    # device = cuda.get_current_device()\n",
        "    # device.reset()\n",
        "    return opposite_sentences\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xVJrpFICIOU1"
      },
      "outputs": [],
      "source": [
        "# # Example usage\n",
        "# reference_sentences = [\n",
        "#     'Camera quality is great.',\n",
        "#     'Resolution of images is amazing.',\n",
        "#     'Shutter speed is great.',\n",
        "#     'I like the images taken from it.',\n",
        "#     'The color reproduction is excellent.',\n",
        "#     'Camera is impressive.',\n",
        "#     'The pictures look sleek and modern.',\n",
        "#     'The camera app is user-friendly.',\n",
        "#     'Low light performance is superb.',\n",
        "#     'The autofocus is very fast.'\n",
        "# ]\n",
        "# opposite_sentences = generate_opposite_sentences(reference_sentences)\n",
        "# for i, sentence in enumerate(opposite_sentences):\n",
        "#     print(f'{i}. '+sentence)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7V8JlLSOIOU1"
      },
      "source": [
        "## Sentence Generation given reference (Mistral)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_YYJMVsL2i-K",
        "outputId": "31423ee4-5537-4b10-d806-86d86867b094"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n"
          ]
        }
      ],
      "source": [
        "# from google.colab import userdata\n",
        "# access_token=userdata.get('Hugging_Face_access_token')\n",
        "import nltk\n",
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
        "# Initialize the sentiment analyzer\n",
        "nltk.download('vader_lexicon')\n",
        "sid = SentimentIntensityAnalyzer()\n",
        "def is_positive(sentence):\n",
        "    sentiment_scores = sid.polarity_scores(sentence)\n",
        "    return sentiment_scores['compound'] > 0.05\n",
        "\n",
        "def is_negative(sentence):\n",
        "    sentiment_scores = sid.polarity_scores(sentence)\n",
        "    return sentiment_scores['compound'] < -0.05"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QXpYF3vhIOU2"
      },
      "outputs": [],
      "source": [
        "def generate_similar_sentences(reference_sentences, topic, num_sentences=50, pos_neg='positive'):\n",
        "    model, tokenizer = load_mistral()\n",
        "    if type(reference_sentences)!= type(['']):\n",
        "      reference_sentences=[reference_sentences]\n",
        "    stopping_counter = 0\n",
        "    gen_sentences=[]\n",
        "    generated_sent=len(gen_sentences)\n",
        "    while generated_sent <= num_sentences:\n",
        "\n",
        "\n",
        "      reference_sents= reference_sentences + gen_sentences\n",
        "\n",
        "      temp='\\n'.join(reference_sents)\n",
        "\n",
        "      prompt=f\"\"\"Give me exactly {num_sentences-generated_sent} different sentences in context of these given reference sentences,\n",
        "      NOTE:\n",
        "      1. The sentences should be overall {pos_neg} in sentiment about the context and not just sentiment-less sentences.\n",
        "      2. Stick to the topic: {topic} and no redundant words like 'ability to'\n",
        "      3. Paraphrasing is not allowed, make sure each generated sentence is slightly different from each other and talks about slightly different aspect taken from reference sentences\n",
        "      4. the count of sentences you generate must be exactly {num_sentences-generated_sent}, no less!\n",
        "      here are the sentences generate exactly {num_sentences-generated_sent} more according to instructions :\\n\\n {temp}\n",
        "      \"\"\"\n",
        "\n",
        "      messages = [\n",
        "      {\n",
        "          \"role\": \"user\",\n",
        "      \"content\": prompt},\n",
        "\n",
        "      ]\n",
        "\n",
        "      inputs = tokenizer.apply_chat_template(messages, return_tensors=\"pt\").to(\"cuda\")\n",
        "\n",
        "      outputs = model.generate(inputs,\n",
        "                              max_new_tokens=8000,\n",
        "                              temperature=0.1,\n",
        "                              top_p=0.99,\n",
        "                              do_sample = True,\n",
        "                              pad_token_id=tokenizer.eos_token_id)\n",
        "\n",
        "      res=tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "\n",
        "\n",
        "\n",
        "      res_sentences=re.split(r'\\d+\\.', res[len(prompt):])\n",
        "\n",
        "      for i in res_sentences:\n",
        "          if i.strip()=='':\n",
        "              continue\n",
        "          if pos_neg.lower() == 'positive' and is_positive(i.strip()):\n",
        "              gen_sentences.append(i.strip())\n",
        "          elif pos_neg.lower() == 'negative' and is_negative(i.strip()):\n",
        "              gen_sentences.append(i.strip())\n",
        "          # print(i.strip())\n",
        "      generated_sent = len(gen_sentences)\n",
        "      stopping_counter += 1\n",
        "      if stopping_counter == 5:\n",
        "        break\n",
        "    del model\n",
        "    del tokenizer\n",
        "    del outputs\n",
        "    del inputs\n",
        "    torch.cuda.empty_cache()\n",
        "    gc.collect()\n",
        "    return gen_sentences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "itcuDZm0IOU3"
      },
      "outputs": [],
      "source": [
        "# sentences = [\n",
        "#     'Camera quality is great.',\n",
        "#     'Resolution of images is amazing.',\n",
        "#     'Shutter speed is great.',\n",
        "#     'I like the images taken from it.',\n",
        "#     'The color reproduction is excellent.',\n",
        "#     'Camera is impressive.',\n",
        "#     'The pictures look sleek and modern.',\n",
        "#     'The camera app is user-friendly.',\n",
        "#     'Low light performance is superb.',\n",
        "#     'The autofocus is very fast.'\n",
        "# ]\n",
        "\n",
        "# res = generate_similar_sentences(sentences, 'camera', num_sentences=50, pos_neg='positive')\n",
        "# for i in res:\n",
        "#     print(i)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IT2jwNobNEos"
      },
      "outputs": [],
      "source": [
        "# len(res)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5PJNrCW3NAbO"
      },
      "source": [
        "# Main Code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WlGkENTrczO6"
      },
      "outputs": [],
      "source": [
        "Subdom_re_dict2={}\n",
        "i=0\n",
        "for j in Subdom_re_dict:\n",
        "    i+=1\n",
        "    if i<=30:\n",
        "      continue\n",
        "    Subdom_re_dict2[j]=Subdom_re_dict[j]\n",
        "    if i==37:\n",
        "        break\n",
        "# Subdom_re_dict2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CaeXm9OxtAda",
        "outputId": "286507cd-ecfc-4dc8-c8d0-2e289adf9abe"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rOngoing generation:   0%|          | 0/7 [00:00<?, ?it/s]Unused kwargs: ['_load_in_4bit', '_load_in_8bit', 'quant_method']. These kwargs are not used in <class 'transformers.utils.quantization_config.BitsAndBytesconfig'>.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/quantizers/auto.py:174: UserWarning: You passed `quantization_config` or equivalent parameters to `from_pretrained` but the model you're loading already has a `quantization_config` attribute. The `quantization_config` from the model will be used.\n",
            "  warnings.warn(warning_msg)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ongoing wide[- ]{0,3}angle\n",
            "Camera\n",
            "1.0    4\n",
            "Name: count, dtype: int64\n",
            "Case 3 for  wide[- ]{0,3}angle\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Unused kwargs: ['_load_in_4bit', '_load_in_8bit', 'quant_method']. These kwargs are not used in <class 'transformers.utils.quantization_config.BitsAndBytesconfig'>.\n",
            "Ongoing generation:  14%|█▍        | 1/7 [03:29<20:54, 209.10s/it]Unused kwargs: ['_load_in_4bit', '_load_in_8bit', 'quant_method']. These kwargs are not used in <class 'transformers.utils.quantization_config.BitsAndBytesconfig'>.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ongoing \\bvide?o?s?\\b(?!.*\\bimages?\\b|.*\\bpictures?\\b|.*\\bpics?\\b|.*\\bportraits?\\b|.*\\bphotos?\\b).*\\bm?i?d?nightt?i?m?e?\\b(?!.*day|.*\\bimages?\\b|.*\\bpictures?\\b|.*\\bpics?\\b|.*\\bportraits?\\b|.*\\bphotos?\\b)|\\bm?i?d?nightt?i?m?e?\\b(?!.*\\bimages?\\b|.*\\bpictures?\\b|.*\\bpics?\\b|.*\\bportraits?\\b|.*\\bphotos?\\b).*\\bvide?o?s?\\b(?!.*day|.*\\bimages?\\b|.*\\bpictures?\\b|.*\\bpics?\\b|.*\\bportraits?\\b|.*\\bphotos?\\b)\n",
            "Camera\n",
            " 1.0    2\n",
            "-1.0    1\n",
            "Name: count, dtype: int64\n",
            "Case 3 for  \\bvide?o?s?\\b(?!.*\\bimages?\\b|.*\\bpictures?\\b|.*\\bpics?\\b|.*\\bportraits?\\b|.*\\bphotos?\\b).*\\bm?i?d?nightt?i?m?e?\\b(?!.*day|.*\\bimages?\\b|.*\\bpictures?\\b|.*\\bpics?\\b|.*\\bportraits?\\b|.*\\bphotos?\\b)|\\bm?i?d?nightt?i?m?e?\\b(?!.*\\bimages?\\b|.*\\bpictures?\\b|.*\\bpics?\\b|.*\\bportraits?\\b|.*\\bphotos?\\b).*\\bvide?o?s?\\b(?!.*day|.*\\bimages?\\b|.*\\bpictures?\\b|.*\\bpics?\\b|.*\\bportraits?\\b|.*\\bphotos?\\b)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Unused kwargs: ['_load_in_4bit', '_load_in_8bit', 'quant_method']. These kwargs are not used in <class 'transformers.utils.quantization_config.BitsAndBytesconfig'>.\n",
            "Ongoing generation:  29%|██▊       | 2/7 [08:13<21:05, 253.19s/it]Unused kwargs: ['_load_in_4bit', '_load_in_8bit', 'quant_method']. These kwargs are not used in <class 'transformers.utils.quantization_config.BitsAndBytesconfig'>.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ongoing (?:\\bimages?\\b|\\bpictures?\\b|\\bpics?\\b|\\bportraits?\\b|\\bphotos?\\b).*\\bvide?o?s?\\b.*\\bm?i?d?dayt?i?m?e?\\b|\\bvide?o?s?\\b.*(?:\\bimages?\\b|\\bpictures?\\b|\\bpics?\\b|\\bportraits?\\b|\\bphotos?\\b).*\\bm?i?d?dayt?i?m?e?\\b|\\bm?i?d?dayt?i?m?e?\\b.*(?:\\bimages?\\b|\\bpictures?\\b|\\bpics?\\b|\\bportraits?\\b|\\bphotos?\\b).*\\bvide?o?s?\\b|\\bm?i?d?dayt?i?m?e?\\b.*\\bvide?o?s?\\b.*(?:\\bimages?\\b|\\bpictures?\\b|\\bpics?\\b|\\bportraits?\\b|\\bphotos?\\b)\n",
            "Camera\n",
            "1.0    4\n",
            "Name: count, dtype: int64\n",
            "Case 3 for  (?:\\bimages?\\b|\\bpictures?\\b|\\bpics?\\b|\\bportraits?\\b|\\bphotos?\\b).*\\bvide?o?s?\\b.*\\bm?i?d?dayt?i?m?e?\\b|\\bvide?o?s?\\b.*(?:\\bimages?\\b|\\bpictures?\\b|\\bpics?\\b|\\bportraits?\\b|\\bphotos?\\b).*\\bm?i?d?dayt?i?m?e?\\b|\\bm?i?d?dayt?i?m?e?\\b.*(?:\\bimages?\\b|\\bpictures?\\b|\\bpics?\\b|\\bportraits?\\b|\\bphotos?\\b).*\\bvide?o?s?\\b|\\bm?i?d?dayt?i?m?e?\\b.*\\bvide?o?s?\\b.*(?:\\bimages?\\b|\\bpictures?\\b|\\bpics?\\b|\\bportraits?\\b|\\bphotos?\\b)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Unused kwargs: ['_load_in_4bit', '_load_in_8bit', 'quant_method']. These kwargs are not used in <class 'transformers.utils.quantization_config.BitsAndBytesconfig'>.\n",
            "Ongoing generation:  43%|████▎     | 3/7 [10:31<13:23, 200.82s/it]Unused kwargs: ['_load_in_4bit', '_load_in_8bit', 'quant_method']. These kwargs are not used in <class 'transformers.utils.quantization_config.BitsAndBytesconfig'>.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ongoing Space Zoom\n",
            "Camera\n",
            "1.0    1\n",
            "Name: count, dtype: int64\n",
            "Case 3 for  Space Zoom\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Unused kwargs: ['_load_in_4bit', '_load_in_8bit', 'quant_method']. These kwargs are not used in <class 'transformers.utils.quantization_config.BitsAndBytesconfig'>.\n",
            "Ongoing generation:  57%|█████▋    | 4/7 [12:42<08:39, 173.25s/it]Unused kwargs: ['_load_in_4bit', '_load_in_8bit', 'quant_method']. These kwargs are not used in <class 'transformers.utils.quantization_config.BitsAndBytesconfig'>.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ongoing (?:\\bimages?\\b|\\bpictures?\\b|\\bpics?\\b|\\bportraits?\\b|\\bphotos?\\b)(?!.*vide?o?s?\\b).*\\bdaylight\\b(?!.*day|.*vide?o?s?\\b)|\\bdaylight\\b(?!.*vide?o?s?\\b).*(?:\\bimages?\\b|\\bpictures?\\b|\\bpics?\\b|\\bportraits?\\b|\\bphotos?\\b)(?!.*day|.*vide?o?s?\\b)\n",
            "Camera\n",
            "1.0    1\n",
            "Name: count, dtype: int64\n",
            "Case 3 for  (?:\\bimages?\\b|\\bpictures?\\b|\\bpics?\\b|\\bportraits?\\b|\\bphotos?\\b)(?!.*vide?o?s?\\b).*\\bdaylight\\b(?!.*day|.*vide?o?s?\\b)|\\bdaylight\\b(?!.*vide?o?s?\\b).*(?:\\bimages?\\b|\\bpictures?\\b|\\bpics?\\b|\\bportraits?\\b|\\bphotos?\\b)(?!.*day|.*vide?o?s?\\b)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Unused kwargs: ['_load_in_4bit', '_load_in_8bit', 'quant_method']. These kwargs are not used in <class 'transformers.utils.quantization_config.BitsAndBytesconfig'>.\n",
            "Ongoing generation:  71%|███████▏  | 5/7 [15:53<05:59, 179.59s/it]Unused kwargs: ['_load_in_4bit', '_load_in_8bit', 'quant_method']. These kwargs are not used in <class 'transformers.utils.quantization_config.BitsAndBytesconfig'>.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ongoing mega \\bpixel\n",
            "Camera\n",
            "1.0    1\n",
            "Name: count, dtype: int64\n",
            "Case 3 for  mega \\bpixel\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Unused kwargs: ['_load_in_4bit', '_load_in_8bit', 'quant_method']. These kwargs are not used in <class 'transformers.utils.quantization_config.BitsAndBytesconfig'>.\n",
            "Ongoing generation:  86%|████████▌ | 6/7 [18:38<02:54, 174.57s/it]Unused kwargs: ['_load_in_4bit', '_load_in_8bit', 'quant_method']. These kwargs are not used in <class 'transformers.utils.quantization_config.BitsAndBytesconfig'>.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ongoing (?:\\bimages?\\b|\\bpictures?\\b|\\bpics?\\b|\\bportraits?\\b|\\bphotos?\\b).*\\bvide?o?s?\\b.*\\bm?i?d?nightt?i?m?e?\\b|\\bvide?o?s?\\b.*(?:\\bimages?\\b|\\bpictures?\\b|\\bpics?\\b|\\bportraits?\\b|\\bphotos?\\b).*\\bm?i?d?nightt?i?m?e?\\b|\\bm?i?d?nightt?i?m?e?\\b.*(?:\\bimages?\\b|\\bpictures?\\b|\\bpics?\\b|\\bportraits?\\b|\\bphotos?\\b).*\\bvide?o?s?\\b|\\bm?i?d?nightt?i?m?e?\\b.*\\bvide?o?s?\\b.*(?:\\bimages?\\b|\\bpictures?\\b|\\bpics?\\b|\\bportraits?\\b|\\bphotos?\\b)\n",
            "Camera\n",
            "1.0    2\n",
            "Name: count, dtype: int64\n",
            "Case 3 for  (?:\\bimages?\\b|\\bpictures?\\b|\\bpics?\\b|\\bportraits?\\b|\\bphotos?\\b).*\\bvide?o?s?\\b.*\\bm?i?d?nightt?i?m?e?\\b|\\bvide?o?s?\\b.*(?:\\bimages?\\b|\\bpictures?\\b|\\bpics?\\b|\\bportraits?\\b|\\bphotos?\\b).*\\bm?i?d?nightt?i?m?e?\\b|\\bm?i?d?nightt?i?m?e?\\b.*(?:\\bimages?\\b|\\bpictures?\\b|\\bpics?\\b|\\bportraits?\\b|\\bphotos?\\b).*\\bvide?o?s?\\b|\\bm?i?d?nightt?i?m?e?\\b.*\\bvide?o?s?\\b.*(?:\\bimages?\\b|\\bpictures?\\b|\\bpics?\\b|\\bportraits?\\b|\\bphotos?\\b)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Unused kwargs: ['_load_in_4bit', '_load_in_8bit', 'quant_method']. These kwargs are not used in <class 'transformers.utils.quantization_config.BitsAndBytesconfig'>.\n",
            "Ongoing generation: 100%|██████████| 7/7 [20:51<00:00, 178.77s/it]\n"
          ]
        }
      ],
      "source": [
        "#Main code for Sentence generation on condition\n",
        "import warnings\n",
        "\n",
        "# Suppress specific warnings\n",
        "warnings.filterwarnings(\"ignore\", message=\"Unused kwargs: .*['quant_method']. These kwargs are not used in .*\")\n",
        "warnings.filterwarnings(\"ignore\", message=\"The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior.\")\n",
        "warnings.filterwarnings(\"ignore\", message=\"Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\")\n",
        "\n",
        "\n",
        "id = 0\n",
        "min_sentence_per_regex= 10\n",
        "result={}\n",
        "intent='Camera'\n",
        "\n",
        "# for i in Subdom_re_dict:\n",
        "for i in tqdm(Subdom_re_dict2, desc=\"Ongoing generation\"):\n",
        "    \"\"\"\n",
        "    temp_df example:\n",
        "\n",
        "    Data columns (total 3 columns):\n",
        " #   Column  Non-Null Count  Dtype\n",
        "---  ------  --------------  -----\n",
        " 0   UID     129 non-null    int64\n",
        " 1   Split   129 non-null    object\n",
        " 2   Camera  129 non-null    float64\n",
        "    \"\"\"\n",
        "\n",
        "    temp_df=pd.DataFrame(Subdom_re_dict2[i])\n",
        "    print(f'Ongoing {i}')\n",
        "    print(temp_df[intent].value_counts())\n",
        "\n",
        "    #Getting val counts\n",
        "    val_counts=temp_df[intent].value_counts().to_dict()\n",
        "\n",
        "    #Getting +1 and -1 value counts\n",
        "    if 1 in val_counts:\n",
        "        val_count_for_plus_one=val_counts[1]\n",
        "    else:\n",
        "        val_count_for_plus_one=0\n",
        "\n",
        "    if -1 in val_counts:\n",
        "        val_count_for_minus_one=val_counts[-1]\n",
        "    else:\n",
        "        val_count_for_minus_one=0\n",
        "\n",
        "    #Case 1: when value count are greater than 500 hence we do opposite sentence conversion directly\n",
        "    if max(val_count_for_plus_one, val_count_for_minus_one)>500:\n",
        "        print('Case 1: for ', i)\n",
        "        plus_sentences = temp_df[temp_df[intent]==1]['Split'].to_list()\n",
        "        minus_sentences = temp_df[temp_df[intent]==-1]['Split'].to_list()\n",
        "\n",
        "        plus_opp_sent = generate_opposite_sentences(plus_sentences)\n",
        "        minus_opp_sent = generate_opposite_sentences(minus_sentences)\n",
        "        overall_opp_sent = plus_opp_sent + minus_opp_sent\n",
        "\n",
        "        sentiments = [-1]*len(plus_opp_sent)+[1]*len(minus_opp_sent)\n",
        "\n",
        "        oppdf = pd.DataFrame({'UID': [f'Opp1_{id+k}' for k in range(len(overall_opp_sent))], 'Split': overall_opp_sent, f'{intent}':sentiments})\n",
        "        id+=len(overall_opp_sent)\n",
        "        fin_df=pd.concat([temp_df, oppdf])\n",
        "        fin_df.drop_duplicates(subset='Split', inplace=True)\n",
        "        result[i]=fin_df\n",
        "        # continue\n",
        "\n",
        "    else:\n",
        "\n",
        "        #Case 2: no sentence present in data for given regex hence nothing much can be done at this point\n",
        "        if val_count_for_plus_one==0 and val_count_for_minus_one==0:\n",
        "            print('No data for ', i)\n",
        "            print(temp_df[intent].value_counts())\n",
        "            continue\n",
        "\n",
        "        #Case 3: if both of them are less than min sentence per regex required\n",
        "        if max([val_count_for_plus_one, val_count_for_minus_one]) < min_sentence_per_regex:\n",
        "            print('Case 3 for ', i)\n",
        "            sentences = temp_df['Split'].to_list()\n",
        "\n",
        "            pos_gen_sent = generate_similar_sentences(sentences, intent, min_sentence_per_regex - val_count_for_plus_one, 'positive')\n",
        "            neg_gen_sent = generate_similar_sentences(sentences, intent, min_sentence_per_regex - val_count_for_minus_one, 'negative')\n",
        "\n",
        "            overall_gen_sent = pos_gen_sent + neg_gen_sent\n",
        "            sentiments = [1]*len(pos_gen_sent)+[-1]*len(neg_gen_sent)\n",
        "            resdf = pd.DataFrame({'UID': [f'Gen3_{id+k}' for k in range(len(overall_gen_sent))], 'Split': overall_gen_sent, f'{intent}':sentiments})\n",
        "\n",
        "            fin_df=pd.concat([temp_df, resdf])\n",
        "            fin_df.drop_duplicates(subset='Split', inplace=True)\n",
        "\n",
        "            id+=len(overall_gen_sent)\n",
        "            result[i]=fin_df\n",
        "            continue\n",
        "\n",
        "        #Case 4: either of them is greater min requirement hence we need to generate len(+1) sentences for -1 and vice versa for len(-1) sentences for +1\n",
        "        elif val_count_for_plus_one>val_count_for_minus_one:\n",
        "\n",
        "            #Ref sentenes\n",
        "            if not val_count_for_plus_one<=2:\n",
        "                    plus_ref_sentences = temp_df[temp_df[intent]==1]['Split'].to_list()[min(val_count_for_plus_one, 10)]\n",
        "            else:\n",
        "                minus_sentences = temp_df[temp_df[intent]==-1]['Split'].to_list()[min(val_count_for_minus_one, 10)]\n",
        "                plus_ref_sentences = generate_opposite_sentences(minus_sentences)\n",
        "\n",
        "            if not val_count_for_minus_one<=2:\n",
        "                minus_ref_sentences = temp_df[temp_df[intent]==-1]['Split'].to_list()\n",
        "                minus_ref_sentences = minus_ref_sentences[:min(val_count_for_minus_one, 10)]\n",
        "            else:\n",
        "                plus_sentences = temp_df[temp_df[intent]==1]['Split'].to_list()[min(val_count_for_plus_one, 10)]\n",
        "                minus_ref_sentences = generate_opposite_sentences(plus_sentences)\n",
        "\n",
        "            #Case 4.1: If both are less than 50, in that case we can just use generation function directly to generate required sentences\n",
        "            if max(val_count_for_plus_one, val_count_for_minus_one) <= 50:\n",
        "                plus_gen_sent = generate_similar_sentences(plus_ref_sentences, intent, val_count_for_minus_one, 'positive')\n",
        "                minus_gen_sent = generate_similar_sentences(minus_ref_sentences, intent, val_count_for_plus_one, 'negative')\n",
        "\n",
        "            #Case 4.2 either of them is greater than 50 and our upper cap for generation is 50 so we paraphrase some sentences\n",
        "            elif max(val_count_for_plus_one, val_count_for_minus_one) > 50:\n",
        "                if val_count_for_minus_one<=50:\n",
        "                    plus_gen_sent = generate_similar_sentences(plus_ref_sentences, intent, val_count_for_minus_one, 'positive')\n",
        "                else:\n",
        "\n",
        "                    plus_gen = generate_similar_sentences(plus_ref_sentences, intent, 50, 'positive')\n",
        "\n",
        "                    reference_sentences = plus_ref_sentences[:min(val_count_for_minus_one-50, len(plus_ref_sentences))]\n",
        "\n",
        "                    rem_plus = generate_paraphrased_sentences(reference_sentences, val_count_for_minus_one-50, 1, 'positive')\n",
        "                    plus_gen_sent = plus_gen + rem_plus\n",
        "\n",
        "                if val_count_for_plus_one<=50:\n",
        "                    minus_gen_sent = generate_similar_sentences(minus_ref_sentences, intent, val_count_for_plus_one, 'negative')\n",
        "                else:\n",
        "                    minus_gen = generate_similar_sentences(minus_ref_sentences, intent, 50, 'negative')\n",
        "\n",
        "                    reference_sentences = minus_ref_sentences[:min(val_count_for_plus_one-50, len(minus_ref_sentences))]\n",
        "\n",
        "                    rem_minus = generate_paraphrased_sentences(reference_sentences, val_count_for_plus_one-50, 1, 'negative')\n",
        "                    minus_gen_sent = minus_gen + rem_minus\n",
        "\n",
        "            overall_gen_sent = plus_gen_sent + minus_gen_sent\n",
        "            sentiments = [1]*len(plus_gen_sent)+[-1]*len(minus_gen_sent)\n",
        "            resdf = pd.DataFrame({'UID': [f'Gen4_{id+k}' for k in range(len(overall_gen_sent))], 'Split': overall_gen_sent, f'{intent}':sentiments})\n",
        "\n",
        "\n",
        "            fin_df=pd.concat([temp_df, resdf])\n",
        "            fin_df.drop_duplicates(subset='Split', inplace=True)\n",
        "\n",
        "            id+=len(overall_gen_sent)\n",
        "            result[i]=fin_df\n",
        "\n",
        "            # continue\n",
        "    print(fin_df[intent].value_counts())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LBwoL24ODDze"
      },
      "outputs": [],
      "source": [
        "with open('/content/drive/Shareddrives/sentence_genration/misc/Camera_generated_29_Jul_Part7.pkl', 'wb') as f:\n",
        "  pickle.dump(result, f)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "PMXnx-kfgqnH",
        "myIsitCxgb56",
        "njUx7_FqIOUu"
      ],
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
